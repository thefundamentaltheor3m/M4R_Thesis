\section{A Metaprogramming Approach}

\begin{comment}
Begin by saying a few words about what metaprogramming is. Then go into subsections. Idea:
1. Establish difficulty of doing computations in \C. Give examples, yes, but also stress that existing automation was unable to unpack the structural nuances of the way \C is defined. Also maybe talk about the whole "is I a numeral" debate, but I think this might be a rabbit-hole...
2. Talk about the algorithm behind norm_numI. Talk about the original version we worked on with Heather and Edison at/after metaprogramming and at Xena.
3. Say something about what Heather's latest modifications look like. Maybe also talk about how the approach can be generalised to quaternion algebras or splitting fields (what's similar and what's different between norm_numI and these things), but don't talk about the maths of either of these. Stress that this is still under development, and that this opens the door to a world of metaprogramming possibilities.
\end{comment}

In this section, we discuss an unexpected biproduct of this project: the development of a normalisation-simplification automation for performing computations in the complex numbers.

Lean, like other interactive theorem provers, primarily interacts with its users through \textbf{tactics}. Fundamentally, the proof of a theorem in Lean is given by a \textbf{proof term}, which can be thought of as a concise expression that captures the information of how the hypotheses or inputs of the theorem are transformed into its conclusion by giving exactly the conclusion into which these inputs are transformed. A tactic is a command that, when invoked by a Lean user, performs a step in the construction of the proof term for a theorem.

The most basic tactics can be thought of as being `syntax sugar' rather than invocations of computation or reasoning algorithms. Consider the following code.
\begin{lstlisting}[caption=A tactic-mode proof of the associativity of $\land$, label=Ch5:Listing:And_assoc_tactic]
example (P Q R : Prop) : P ∧ (Q ∧ R) ↔ (P ∧ Q) ∧ R := by
  constructor
  · intro h
    constructor
    · constructor
      · exact h.1
      · exact h.2.1
    · exact h.2.2
  · intro h
    constructor
    · exact h.1.1
    · constructor
      · exact h.1.2
      · exact h.2
\end{lstlisting}

This proof demonstrates how the \lstinline|constructor|, \lstinline|intro| and \lstinline|exact| tactics work. These tactics give the Lean compiler the following instructions:
\begin{itemize}
    \item \lstinline|constructor|: ``Prove the goal by proving the two statements it consists of." It works on conjunctions and biconditionals, that is, if the goal is of the form \lstinline|A ∧ B|, then \lstinline|constructor| replaces it with two goals, namely, \lstinline|A| and \lstinline|B|, and if the goal is of the form \lstinline|A ↔ B|, then \lstinline|constructor| replaces it with two goals, namely, \lstinline|A → B| and \lstinline|B → A|.
    
    \item \lstinline|intro|: ``Prove the goal by introducing the assumption term and proving the conclusion term." It works on implications and universal quantifications, that is, if the goal is of the form \lstinline|A → B|, then \lstinline|intro h| introduces an assumption \lstinline|h| of \lstinline|A| and replaces the goal with \lstinline|B|, and if the goal is of the form \lstinline|∀ (x : A), B|, then \lstinline|intro a| introduces term \lstinline|a| of type \lstinline|A| and replaces the goal with \lstinline|B|.

    \item \lstinline|exact|: ``Prove the goal with the following." It works on any goal where the proof of that goal is already known, that is, if the goal is \verb|B| and some proof \lstinline|h| of \lstinline|B| is already known, then \lstinline|exact h| proves the goal with \lstinline|h|.
\end{itemize}

In addition, the terms \lstinline|h.1|, \lstinline|h.2.1|, etc are shorthand for ``the first constituent of \lstinline|h|'', ``the first constituent of (the second constituent of \lstinline|h|)'', etc, where by ``first constituent'' and ``second constituent'', we mean the terms respectively to the left and right of the $\land$ symbol.

What the tactics used in \Cref{Ch5:Listing:And_assoc_tactic} are actually doing is constructing the following \textbf{term-mode proof} of the same result.

\begin{lstlisting}[caption=A term-mode proof of the associativity of $\land$, label=Ch5:Listing:And_assoc_term]
example (P Q R : Prop) : P ∧ (Q ∧ R) ↔ (P ∧ Q) ∧ R :=
  ⟨fun h ↦ ⟨⟨h.1, h.2.1⟩, h.2.2⟩,
   fun h ↦ ⟨h.1.1, ⟨h.1.2, h.2⟩⟩⟩
\end{lstlisting}

% Try and end the discussion here. The point we were trying to make is that tactics generate proof terms. I think that point has been made! The remainder of this section can maybe be a discussion in an appendix. We can say something like "here's some fun facts about theorem proving in Lean" and include this and maybe even some other fun stuff from the book

This proof is significantly shorter than the tactic-mode proof see in \Cref{Ch5:Listing:And_assoc_tactic}. While the code is arguably less readable than the tactic-mode proof, it is not too difficult to dissect:
\begin{itemize}
    \item The \lstinline|constructor| occurrences in \Cref{Ch5:Listing:And_assoc_tactic} correspond to the \textit{anonymous constructors} \lstinline|⟨,⟩| in \Cref{Ch5:Listing:And_assoc_term}.

    \item The \lstinline|intro h| occurrences in \Cref{Ch5:Listing:And_assoc_tactic} correspond to the function definitions \lstinline|fun h ↦| in \Cref{Ch5:Listing:And_assoc_term}.

    \item The \lstinline|exact| occurrences in \Cref{Ch5:Listing:And_assoc_tactic} correspond to the terms inside the anonymous constructors in \Cref{Ch5:Listing:And_assoc_term}.
\end{itemize}

In particular, the proof in \Cref{Ch5:Listing:And_assoc_term} consists solely of functions and constructors. No tactics occur anywhere in the argument (note the absence of the \lstinline|by| keyword, which marks the beginning of a tactic-mode proof).

It turns out that \Cref{Ch5:Listing:And_assoc_term} still contains some syntax sugar. It is possible to use helper lemmas like \verb|Iff.intro| and \verb|And.intro| to avoid using the anonymous constructors, but a proof term completely devoid of the constructor syntax would look like the following.

\begin{lstlisting}[caption=A proof term for the associativity of $\land$, label=Ch5:Listing:And_assoc_proof_term, escapeinside=``]
example (P Q R : Prop) : P ∧ (Q ∧ R) ↔ (P ∧ Q) ∧ R := {
  mp := fun a ↦ {
    left := {
      left := And.casesOn a fun left right ↦ And.casesOn right fun _ _ ↦ left
      right := And.casesOn a fun _ right ↦ And.casesOn right fun left _ ↦ left
    }
    right := And.casesOn a fun _ right ↦ And.casesOn right fun _ right ↦ right
  }
  mpr := fun a ↦ {
    left := And.casesOn a fun left _right ↦ And.casesOn left fun left _ ↦ left `\newpage`
    right := {
      left := And.casesOn a fun left _ ↦ And.casesOn left fun _ right ↦ right
      right := And.casesOn a fun left right ↦ And.casesOn left fun _ _ ↦ right
    }
  }
}
\end{lstlisting}

Proof terms, as we can see from \Cref{Ch5:Listing:And_assoc_proof_term}, are often long and do not clearly communicate the mathematical ideas they represent. Tactics overcome this by constructing proof terms without revealing them to the user. Indeed, there are tactics that serve as more than just syntax sugar: for example, results in intuitionistic propositional logic (such as the associativity of $\land$) can be proved by the tactic \lstinline|itauto|. That is, the following code compiles.


\begin{lstlisting}[caption=A one-line tactic proof for the associativity of $\land$, label=Ch5:Listing:And_assoc_itauto]
example (P Q R : Prop) : P ∧ (Q ∧ R) ↔ (P ∧ Q) ∧ R := by itauto
\end{lstlisting}

Other tactics like \lstinline|tauto| and \lstinline|simp| also work. The proof term generated by such a tactic can be viewed by typing \lstinline|show_term|.\footnote{For the curious reader, \Cref{Ch5:Listing:And_assoc_proof_term} was generated by repeatedly typing \lstinline|show_term by tauto| inside each field.} For a more detailed explanation of how proof terms and tactics work, see \cite[particularly Chapters 3 and 5]{ThmPfInLean}.

\textbf{Metaprogramming} is the science of writing tactics in Lean. While syntax-sugar tactics are incredibly useful (compare the readability of \Cref{Ch5:Listing:And_assoc_tactic,Ch5:Listing:And_assoc_term,Ch5:Listing:And_assoc_proof_term}), automation tactics often go an even longer way in keeping the focus of nontrivial mathematical proofs on precisely their nontrivial aspects. Given how computationally involved the construction of Viazovska's Magic Function is (as seen in \Cref{Ch4:Chapter}), the author, after a discussions with Macbeth, realised that the most efficient approach to formalising some of the computational aspects of Viazovska's argument was to write a tactic. The first version of this tactic, developed as a collaboration between Macbeth, Xie and the author, with inputs from Mehta, was called \lstinline|norm_numI|.

In the forthcoming subsections, we explore the motivation and technique used to develop \lstinline|norm_numI|, and briefly discuss how the tactic maybe further developed and the scope of its applicability expanded.

\subsection{Complex Computations are Complex}

Computations in general are quite challenging to perform in interactive theorem provers. This is because such languages are designed for \textit{proof} rather than \textit{computation}. Indeed, tactics that simplify goals do not do so merely by simplifying expressions: they construct proofs that the simplified expression is, indeed, equal to the original expression. Existing tactics like \lstinline|norm_num|, \lstinline|simp| and \lstinline|field_simp| do not always do this successfully when the expressions in question are in $\C$. \lstinline|simp| and \lstinline|field_simp| are very general tactics that work in a wide variety of settings. They both work by constructing a special set of equality or biconditional lemmas by sifting through the library and performing repeated rewrite operations to transform the goal into a simpler form. \lstinline|field_simp| is specifically designed to simplify expressions in fields, and can handle operations like clearing denominators. However, it does not have access to the particularities of the field in question (such as the fact that $i^2 = -1$ in $\C$). The tactic that we will be most interested in, specifically because it is designed to handle simplifications of \textit{numerals} in \textit{specific} settings, is \lstinline|norm_num|.

\lstinline|norm_num| is a tactic that handles expressions involving numerals. It works best in $\N$, $\Z$ and $\Q$. For example, it handles the following.
\begin{lstlisting}[caption={\lstinline|norm_num| simplifying expressions in $\N$, $\Z$ and $\Q$}]
example : (1 : ℕ) + 2 + 3 + 4 = 10 := by norm_num
example : (-2 : ℚ) * (3 + 8/9) = -70/9 := by norm_num
example : (-9 : ℤ) + 5 * (6 - 20) = -79 := by norm_num
\end{lstlisting}
It is worth mentioning, however, that \lstinline|norm_num| often has difficulties in $\R$. This is due to the immense technical detail baked into the very definition of $\R$ in Lean, which allows for the existence of transcendental numbers. In the following example, none of \lstinline|norm_num|, \lstinline|field_simp|, \lstinline|ring| and \lstinline|simp| can prove the result in one line, because they are unable to treat $\pi$ as more than a symbol. Indeed, the entire proof rests on a \mathlib\ result, \lstinline|Real.pi_gt_three|.

\begin{lstlisting}[caption=An expression in $\R$ not handled immediately by simplification tactics, label=Ch5:Listing:pi_sub_one_norm_num_fail]
example : (π - 1) / (π - 1) = 1 := by
  have h₁ : (1 : ℝ) < 3 := by norm_num
  have h₂ : 1 ≠ π := ne_of_lt <| h₁.trans pi_gt_three
  have h₃ : π - 1 ≠ 0 := sub_ne_zero_of_ne h₂.symm
  field_simp [h₃]
\end{lstlisting}

Observe, however, that \lstinline|norm_num| \textit{is} able to prove the inequality $1 < 3$ despite it being an expression in $\R$. The reason is that \lstinline|norm_num| can navigate the canonical inclusions from $\N$, $\Z$ and $\Q$ into $\R$, meaning that it can simplify expressions in $\R$ that come from expressions it can simplify in $\N$, $\Z$ or $\Q$.\footnote{We say \lstinline|norm_num| can handle coercions.} It cannot, however, show that $1 < \pi$, because it does not understand $\pi$ \textit{as a numeral}. In $\C$, \lstinline|norm_num| faces this challenge not only with real transcendental numbers like $\pi$ but also with the imaginary constant $i$. Consider the following example.\footnote{Note that in Lean, the imaginary constant is denoted by an uppercase \lstinline|I| instead of a lowercase $i$. We will adhere to standard mathematical conventions and use a lowercase $i$ when referring to the imaginary constant in informal contexts.}

\begin{lstlisting}[caption={A nontrivial computation in $\C$, done formally}, label=Ch5:Listing:long_tactic_pf_example_complex]
example : (1 + I) * (1 + I * I * I) = 2 := by
  simp only [I_mul_I, neg_mul, one_mul, mul_add, mul_one, mul_neg, add_mul, neg_add_rev, neg_neg]
  ring
\end{lstlisting}

Again, \lstinline|simp|, \lstinline|field_simp|, \lstinline|ring| and \lstinline|norm_num| all fail, because $i$, like $\pi$ in \Cref{Ch5:Listing:pi_sub_one_norm_num_fail}, is not handled as a numeral. Observe, however, that $\parenth{1 + i}\parenth{1 + i \cdot i \cdot i}$ lies in $\Z[i]$. This means that if it is expressed as $a + bi$, with $a$ and $b$ both being (not necessarily simplified) real expressions, then in fact, $a$ and $b$ are both images of expressions in $\Z$. This means that \lstinline|norm_num| would be able to individually handle both $a$ and $b$, resulting in a simplified expression of the form $a' + b'i$, with $a'$ and $b'$ being simplified. This suggests that the key to writing a tactic that can simplify expressions like those in \Cref{Ch5:Listing:long_tactic_pf_example_complex} is to find a way to separate them into their real and imaginary parts, which in turn involves navigating the fact that $i^2 = -1$.

\subsection{Normalisation and Simplification}

\subsection{Scope for Further Development}

The benefits of having such a tactic cannot be overstated. There are numerous instances across the project where the collaborators have had to repeatedly prove facts like $1 + i \neq 0$ or clear complex denominators to separate into real and imaginary parts. 